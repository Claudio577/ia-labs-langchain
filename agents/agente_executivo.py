from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from ingest.vector_store import carregar_vector_store
from config import OPENAI_MODEL

def criar_agente_executivo():

    llm = ChatOpenAI(
        model=OPENAI_MODEL,
        temperature=0.2
    )

    vectordb = carregar_vector_store()
    retriever = vectordb.as_retriever()

    prompt = ChatPromptTemplate.from_template("""
    Voc√™ √© o **Agente Executivo IA-Labs**, especialista em:
    - Resumos executivos
    - Insights estrat√©gicos
    - Identifica√ß√£o de riscos e oportunidades
    - Plano de a√ß√£o
    - KPIs
    - Vis√£o consultiva corporativa

    Documentos relevantes:
    {contexto}

    Pergunta:
    {input}

    Gere uma resposta estruturada:

    üéØ Insight principal  
    ‚ö†Ô∏è Riscos identificados  
    üí° Oportunidades observadas  
    üìà KPIs recomendados  
    üß† A√ß√µes sugeridas pela IA-Labs  
    """)

    def executar(texto):
        docs = retriever.get_relevant_documents(texto)
        contexto = "\n\n".join([d.page_content for d in docs])

        return llm.invoke(prompt.format(
            contexto=contexto,
            input=texto
        )).content

    class Wrapper:
        def run(self, texto):
            return executar(texto)

    return Wrapper()
